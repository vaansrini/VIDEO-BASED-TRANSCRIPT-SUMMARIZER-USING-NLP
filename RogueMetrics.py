from rouge import Rouge
import nlpcloud
import asyncio
from sumy.summarizers.lex_rank import LexRankSummarizer
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from nltk import sent_tokenize

def RogueMetrics(original_text, tf_idf_input, lex_rank_input , calc = 0.5 ):
    client = nlpcloud.Client("t5-base-en-generate-headline", "fd35fba7b66e697808196895e7d1cdccab843f84")
    # Returns a json object.
    summary = client.summarization(original_text)

    model_out = [summary["summary_text"]]
    reference = [tf_idf_input]
    rouge = Rouge()


    tf_idf_score = rouge.get_scores(model_out, reference, avg=True)
    tf_idf_score = tf_idf_score[0]['rouge-1']['f'] + tf_idf_score[0]['rouge-2']['f'] + tf_idf_score[0]['rouge-l']['f']
    tf_idf_score = tf_idf_score / 3

    model_out = [summary["summary_text"]]

    reference = [lex_rank_input]

    rouge = Rouge()
    lex_rank_score = rouge.get_scores(model_out, reference, avg=True)
    lex_rank_score = lex_rank_score[0]['rouge-1']['f'] + lex_rank_score[0]['rouge-2']['f'] + lex_rank_score[0]['rouge-l']['f']
    lext_rank_score = lex_rank_score / 3

    if(tf_idf_score > text_rank_score):
        return summary

    return summary




























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































def RogueMetrics(original_text, tf_idf_input, text_rank_input  , percent):
    print("\n Final Summary :  \n")
    client = nlpcloud.Client("pegasus-xsum", "fd35fba7b66e697808196895e7d1cdccab843f84")
    # Returns a json object.
    summarizer = LexRankSummarizer()
    parser = PlaintextParser.from_string(original_text, Tokenizer("english"))
    # Summarize the document with 4 sentences
    sentences = sent_tokenize(original_text)
    total_documents = len(sentences)
    if(percent == 50):
        percent = total_documents / 2
    elif (percent == 25):
        percent = total_documents / 4
    elif (percent == 10):
        percent = total_documents / 10

    summary = summarizer( parser.document , percent )
    print(type(summary))


    return summary